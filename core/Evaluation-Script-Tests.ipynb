{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9705b8b-e21c-4e0c-9fd7-6e6696be1236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2333f459-a51f-463e-8e24-e42134d16734",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.proportion import proportion_confint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdb61245-db8e-4670-990b-54a916d9e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from scipy.stats import norm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1649516-8315-492a-83ff-b5d8d3f4aeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confidenceinterval import accuracy_score, \\\n",
    "    precision_score, \\\n",
    "    recall_score, \\\n",
    "    f1_score\n",
    "\n",
    "from confidenceinterval.utils import get_positive_negative_counts\n",
    "\n",
    "import sklearn.metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2be1cd90-d8eb-42ec-a00b-3d4cb7d63b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wilson_score_interval(tp, fp, fn, metric):\n",
    "    confidence=0.95\n",
    "    x = tp\n",
    "    print(tp, fp, fn, metric)\n",
    "    if metric == \"precision\":\n",
    "        n = tp + fp\n",
    "    elif metric == \"recall\":\n",
    "        n = tp + fn\n",
    "    else:\n",
    "        return (0, 0, 0)\n",
    "\n",
    "    z = norm.ppf(1 - (1 - confidence) / 2)\n",
    "    phat = x / n\n",
    "    center = (x + z ** 2 / 2) / (n + z ** 2)\n",
    "\n",
    "    interval = ((z * np.sqrt(n)) / (n + z ** 2)) * np.sqrt(phat * (1 - phat) + z ** 2 / (4 * n))\n",
    "\n",
    "    lower_bound = center - interval\n",
    "    upper_bound = center + interval\n",
    "    \n",
    "    if phat == 0:\n",
    "        return (0,0,0)\n",
    "    \n",
    "    return round(phat,3), (round(lower_bound,3), round(upper_bound,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab435d33-10c1-497c-8740-093189c55c0e",
   "metadata": {},
   "source": [
    "## Multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3aaf3af6-3094-4c5e-991a-e6272669bbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = [[2, 0, 0, 2, 1, 1, 1, 1,2,2],[2, 0, 1, 0, 1, 0, 1, 1,2,2]]\n",
    "FP, FN, TP, TN, CM = get_positive_negative_counts(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2d180bb-6aeb-4bdc-bc04-7e67ec066431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2, 1, 0]),\n",
       " array([1, 1, 1]),\n",
       " array([1, 3, 3]),\n",
       " array([6, 5, 6]),\n",
       " array([[1, 1, 0],\n",
       "        [1, 3, 0],\n",
       "        [1, 0, 3]]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP, FN, TP, TN, CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "545c5efd-a310-4290-ae2b-ff319a0bee3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 3, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp_sum = TP.sum()\n",
    "fp_sum = FP.sum()\n",
    "fn_sum = FN.sum()\n",
    "tp_sum, fp_sum, fn_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "64838a2d-9fad-4b31-b086-845b6ca266d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7, 0.7, (0.4159742349106746, 0.9840257650893254))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_result = sklearn.metrics.precision_score(y_true, y_pred, average='micro')\n",
    "precision, ci = precision_score(y_true, y_pred, average='micro')\n",
    "sklearn_result, precision, ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f54c0214-5ff2-457d-a42d-0ebe38df51a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7, 0.7, (0.4159742349106746, 0.9840257650893254))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_result = sklearn.metrics.recall_score(y_true, y_pred, average='micro')\n",
    "recall, ci = recall_score(y_true, y_pred, average='micro')\n",
    "sklearn_result, recall, ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b50d825d-bd66-4239-a6f8-f770b34abdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6944444444444443,\n",
       " 0.6944444444444443,\n",
       " (0.5449946838878599, 0.8438942050010287))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_result = sklearn.metrics.precision_score(y_true, y_pred, average='macro')\n",
    "precision, ci = precision_score(y_true, y_pred, average='macro')\n",
    "sklearn_result, precision, ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93f77fae-4784-44be-86eb-66dd4786ed05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " (0.43597160658727707, 0.8973617267460562))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_result = sklearn.metrics.recall_score(y_true, y_pred, average='macro')\n",
    "recall, ci = recall_score(y_true, y_pred, average='macro')\n",
    "sklearn_result, recall, ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1a7a7d60-192a-4505-9bbf-3deb167ca91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.669047619047619,\n",
       " 0.6690476091743198,\n",
       " (0.23963266346377893, 1.0984625548848608))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_result = sklearn.metrics.f1_score(y_true, y_pred, average='macro')\n",
    "f1, ci = f1_score(y_true, y_pred, average='macro')\n",
    "sklearn_result, f1, ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c833c32-2a4b-4707-8cea-276fe445bd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7, (0.4159742349106746, 0.9840257650893254))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micro_f1, ci = f1_score(y_true, y_pred, confidence_level=0.95, average='micro')\n",
    "micro_f1, ci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6ad6e2-d3a8-4e87-8b45-7d9262f62a59",
   "metadata": {},
   "source": [
    "## Binary case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3b46356-4fe2-46d9-8426-2a33d553041d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[6, 1],\n",
       "        [2, 5]]),\n",
       " 5,\n",
       " 1,\n",
       " 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_binary, y_pred_binary = [[0, 0, 0, 0, 0 ,0, 1, 1, 1,1,1,0,1,1],[0, 0, 0, 0, 0 ,0, 1, 1, 1,1,1,1,0,0]]\n",
    "FP, FN, TP, TN, CM = get_positive_negative_counts(y_true_binary, y_pred_binary)\n",
    "\n",
    "tp_sum = TP[1] # TP for recognising 1 correctly!\n",
    "fp_sum = FP[1]\n",
    "fn_sum = FN[1]\n",
    "#TP, FN = TP[1], FN[1]\n",
    "CM, tp_sum, fp_sum, fn_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35c65217-e193-4579-a0ba-2b190e65083c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP [2 1] 1\n",
      "FN [1 2] 2\n"
     ]
    }
   ],
   "source": [
    "print(\"FP\",FP, fp_sum) \n",
    "print(\"FN\", FN, fn_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eff14c44-df5f-42bf-8ec3-5637365962cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43649717781352965, 0.9699466302516933)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test statsmodels.stats.proportion\n",
    "count = tp_sum # nr of successes\n",
    "nobs_precision = tp_sum + fp_sum # nr of trials, precision\n",
    "proportion_confint(count, nobs_precision, alpha=0.05, method='wilson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "261acba1-8591-42b9-878c-d1dbdac5afb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3589344518326191, 0.9177810759959432)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nobs_recall = tp_sum + fn_sum # nr of trials, recall\n",
    "proportion_confint(count, nobs_recall, alpha=0.05, method='wilson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ca89a53-f4d8-49be-8ae1-2388337bf53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('P',\n",
       " 0.8333333333333334,\n",
       " 0.8333333194444447,\n",
       " (0.43649717781352987, 0.9699466302516935))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test sklearn and local library\n",
    "# precision\n",
    "sklearn_result = sklearn.metrics.precision_score(y_true_binary, y_pred_binary, average='binary')\n",
    "precision, ci = precision_score(y_true_binary, y_pred_binary, average='binary', method='wilson')\n",
    "\"P\",sklearn_result, precision, ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bc014ec-9a8f-43b0-8ac6-3d8fd25f1272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1 2 precision\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.833, (0.436, 0.97))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test own implementation\n",
    "wilson_score_interval(tp_sum, fp_sum, fn_sum, metric = \"precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "971bb036-ba5e-4889-8fe1-1595b76c4dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('R',\n",
       " 0.7142857142857143,\n",
       " 0.7142857040816327,\n",
       " (0.35893445183261935, 0.9177810759959433))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall\n",
    "sklearn_result = sklearn.metrics.recall_score(y_true_binary, y_pred_binary, average='binary')\n",
    "recall, ci = recall_score(y_true_binary, y_pred_binary, average='binary', method='wilson')\n",
    "\"R\",sklearn_result, recall, ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a97cc48-7b92-4a18-ae78-d9abf0171c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1 2 recall\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.714, (0.359, 0.918))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wilson_score_interval(tp_sum, fp_sum, fn_sum, metric = \"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c9b727f-65ae-4daf-afce-6b43b173f9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('F1',\n",
       " 0.7692307692307693,\n",
       " 0.7692307692307693,\n",
       " (0.4899279111581648, 1.0485336273033736))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_result = sklearn.metrics.f1_score(y_true_binary, y_pred_binary)\n",
    "binary_f1, ci = f1_score(y_true_binary, y_pred_binary, confidence_level=0.95, average='binary')\n",
    "\"F1\", sklearn_result, binary_f1, ci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f8c02b-32e1-4c00-95f0-67b33d801fa1",
   "metadata": {},
   "source": [
    "# Custom Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0560fa5-f1a3-4b28-a6bb-90a468eae68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.50      1.00      0.67         1\n",
      "     class 1       0.00      0.00      0.00         1\n",
      "     class 2       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.50      0.56      0.49         5\n",
      "weighted avg       0.70      0.60      0.61         5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = [0, 1, 2, 2, 2]\n",
    "y_pred = [0, 0, 2, 2, 1]\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2dd736b9-0437-4005-b4bb-a0326e0d1cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '0 - Remaining',\n",
       " 1: '1 - Non-systematic-review',\n",
       " 2: '2 - Human-non-RCT-non-drug-intervention'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_numerical = {\n",
    "    'Remaining': 0,\n",
    "    'Non-systematic-review': 1,\n",
    "    'Human-non-RCT-non-drug-intervention': 2\n",
    "}\n",
    "numerical_to_label = {v: f\"{v} - {k}\" for k, v in label_to_numerical.items()}\n",
    "numerical_to_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd0efb92-e541-49f5-8e04-7908a2c61e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [0, 1, 2, 2, 2]\n",
    "y_pred = [0, 0, 2, 2, 1]\n",
    "\n",
    "precision, ci = precision_score(y_true_binary, y_pred_binary, average='binary', method='wilson')\n",
    "recall, ci = recall_score(y_true_binary, y_pred_binary, average='binary', method='wilson')\n",
    "binary_f1, ci = f1_score(y_true_binary, y_pred_binary, confidence_level=0.95, average='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6dc58b72-91a3-4068-95df-0471b6611968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_tuple(t, decimals=3):\n",
    "    return tuple(round(num, decimals) for num in t)\n",
    "\n",
    "def classification_report_with_ci(y_true, y_pred, binary_method = 'wilson', round_ndigits=3, numerical_to_label_map = None):\n",
    "    # Unique classes in the dataset\n",
    "    classes = np.unique(y_true)\n",
    "\n",
    "    # Validate that all unique classes are covered in the numerical_to_label_map if provided\n",
    "    if numerical_to_label_map is not None:\n",
    "        missing_labels = [cls for cls in classes if cls not in numerical_to_label_map]\n",
    "        if missing_labels:\n",
    "            raise ValueError(f'Missing labels for classes: {missing_labels}')\n",
    "    \n",
    "    data = []  # List to store row dictionaries\n",
    "    \n",
    "    # Unique classes in the dataset\n",
    "    classes = np.unique(y_true)\n",
    "    \n",
    "    # Calculate precision, recall, f1 for each class treated as binary\n",
    "    for class_ in classes:\n",
    "        y_true_binary = [1 if y == class_ else 0 for y in y_true]\n",
    "        y_pred_binary = [1 if y == class_ else 0 for y in y_pred]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        precision, precision_ci = precision_score(y_true_binary, y_pred_binary, average='binary', method=binary_method)\n",
    "        recall, recall_ci = recall_score(y_true_binary, y_pred_binary, average='binary', method=binary_method)\n",
    "        binary_f1, binary_f1_ci = f1_score(y_true_binary, y_pred_binary, confidence_level=0.95, average='binary')\n",
    "    \n",
    "        class_name = numerical_to_label_map[class_] if (numerical_to_label_map and class_ in numerical_to_label_map) else f'Class {class_}'\n",
    "        support = sum(y_true_binary)\n",
    "\n",
    "        # Create a new row as a DataFrame and append it to the main DataFrame\n",
    "        # Append new row to the list\n",
    "        data.append({\n",
    "            'Class': class_name,\n",
    "            'Precision': round(precision, round_ndigits),\n",
    "            'Recall': round(recall, round_ndigits),\n",
    "            'F1-Score': round(binary_f1, round_ndigits),\n",
    "            'Precision CI': round_tuple(precision_ci, round_ndigits),\n",
    "            'Recall CI': round_tuple(recall_ci, round_ndigits),\n",
    "            'F1-Score CI': round_tuple(binary_f1_ci, round_ndigits),\n",
    "            'Support': support\n",
    "        })\n",
    "    \n",
    "    precision_micro, p_ci_micro = precision_score(y_true, y_pred, average='micro')\n",
    "    precision_macro, p_ci_macro = precision_score(y_true, y_pred, average='macro')\n",
    "    \n",
    "    recall_micro, r_ci_micro = recall_score(y_true, y_pred, average='micro')\n",
    "    recall_macro, r_ci_macro = recall_score(y_true, y_pred, average='macro')\n",
    "    \n",
    "    f1_micro, f1_ci_micro = f1_score(y_true, y_pred, average='micro')\n",
    "    f1_macro, f1_ci_macro = f1_score(y_true, y_pred, average='macro')\n",
    "    \n",
    "    data.append({\n",
    "        'Class': 'micro',\n",
    "        'Precision': round(precision_micro, round_ndigits),\n",
    "        'Recall': round(recall_micro, round_ndigits),\n",
    "        'F1-Score': round(f1_micro, round_ndigits),\n",
    "        'Precision CI': round_tuple(p_ci_micro, round_ndigits),\n",
    "        'Recall CI': round_tuple(r_ci_micro, round_ndigits),\n",
    "        'F1-Score CI': round_tuple(f1_ci_micro, round_ndigits),\n",
    "        'Support' : len(y_true)\n",
    "    })\n",
    "    \n",
    "    data.append({\n",
    "        'Class': 'macro',\n",
    "        'Precision': round(precision_macro,round_ndigits),\n",
    "        'Recall': round(recall_macro,round_ndigits),\n",
    "        'F1-Score': round(f1_macro,round_ndigits),\n",
    "        'Precision CI': round_tuple(p_ci_macro, decimals=round_ndigits),\n",
    "        'Recall CI': round_tuple(r_ci_macro, decimals=round_ndigits),\n",
    "        'F1-Score CI': round_tuple(f1_ci_macro, decimals=round_ndigits),\n",
    "        'Support' : len(y_true)\n",
    "\n",
    "    })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "05d1759d-d837-4735-b2b9-76baf563ddd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision CI</th>\n",
       "      <th>Recall CI</th>\n",
       "      <th>F1-Score CI</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Class 0</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>(0.231, 0.882)</td>\n",
       "      <td>(0.439, 1.0)</td>\n",
       "      <td>(0.408, 1.092)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Class 1</td>\n",
       "      <td>0.889</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.941</td>\n",
       "      <td>(0.565, 0.98)</td>\n",
       "      <td>(0.676, 1.0)</td>\n",
       "      <td>(0.796, 1.086)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Class 2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.800</td>\n",
       "      <td>(0.61, 1.0)</td>\n",
       "      <td>(0.354, 0.879)</td>\n",
       "      <td>(0.562, 1.038)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>micro</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.850</td>\n",
       "      <td>(0.694, 1.006)</td>\n",
       "      <td>(0.694, 1.006)</td>\n",
       "      <td>(0.694, 1.006)</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.830</td>\n",
       "      <td>(0.702, 0.958)</td>\n",
       "      <td>(0.775, 1.002)</td>\n",
       "      <td>(0.548, 1.113)</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Precision  Recall  F1-Score    Precision CI       Recall CI  \\\n",
       "0  Class 0      0.600   1.000     0.750  (0.231, 0.882)    (0.439, 1.0)   \n",
       "1  Class 1      0.889   1.000     0.941   (0.565, 0.98)    (0.676, 1.0)   \n",
       "2  Class 2      1.000   0.667     0.800     (0.61, 1.0)  (0.354, 0.879)   \n",
       "3    micro      0.850   0.850     0.850  (0.694, 1.006)  (0.694, 1.006)   \n",
       "4    macro      0.830   0.889     0.830  (0.702, 0.958)  (0.775, 1.002)   \n",
       "\n",
       "      F1-Score CI  Support  \n",
       "0  (0.408, 1.092)        3  \n",
       "1  (0.796, 1.086)        8  \n",
       "2  (0.562, 1.038)        9  \n",
       "3  (0.694, 1.006)       20  \n",
       "4  (0.548, 1.113)       20  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [0, 1, 2, 2, 2, 1, 1, 1, 0, 2, 2, 1, 0, 2, 2, 1, 2, 2, 1, 1]\n",
    "y_pred = [0, 1, 0, 0, 2, 1, 1, 1, 0, 2, 2, 1, 0, 1, 2, 1, 2, 2, 1, 1]\n",
    "\n",
    "classification_report_with_ci(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f1f528f4-1668-4818-ba55-67d1735d9832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision CI</th>\n",
       "      <th>Recall CI</th>\n",
       "      <th>F1-Score CI</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cherries</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>(0.23, 0.88)</td>\n",
       "      <td>(0.44, 1.0)</td>\n",
       "      <td>(0.41, 1.09)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Olives</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>(0.57, 0.98)</td>\n",
       "      <td>(0.68, 1.0)</td>\n",
       "      <td>(0.8, 1.09)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tangerines</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.80</td>\n",
       "      <td>(0.61, 1.0)</td>\n",
       "      <td>(0.35, 0.88)</td>\n",
       "      <td>(0.56, 1.04)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>micro</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>(0.69, 1.01)</td>\n",
       "      <td>(0.69, 1.01)</td>\n",
       "      <td>(0.69, 1.01)</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.83</td>\n",
       "      <td>(0.7, 0.96)</td>\n",
       "      <td>(0.78, 1.0)</td>\n",
       "      <td>(0.55, 1.11)</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Class  Precision  Recall  F1-Score  Precision CI     Recall CI  \\\n",
       "0    Cherries       0.60    1.00      0.75  (0.23, 0.88)   (0.44, 1.0)   \n",
       "1      Olives       0.89    1.00      0.94  (0.57, 0.98)   (0.68, 1.0)   \n",
       "2  Tangerines       1.00    0.67      0.80   (0.61, 1.0)  (0.35, 0.88)   \n",
       "3       micro       0.85    0.85      0.85  (0.69, 1.01)  (0.69, 1.01)   \n",
       "4       macro       0.83    0.89      0.83   (0.7, 0.96)   (0.78, 1.0)   \n",
       "\n",
       "    F1-Score CI  Support  \n",
       "0  (0.41, 1.09)        3  \n",
       "1   (0.8, 1.09)        8  \n",
       "2  (0.56, 1.04)        9  \n",
       "3  (0.69, 1.01)       20  \n",
       "4  (0.55, 1.11)       20  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_to_label = {\n",
    "    0: \"Cherries\",\n",
    "    1: \"Olives\",\n",
    "    2: \"Tangerines\"\n",
    "}\n",
    "\n",
    "classification_report_with_ci(y_true, y_pred, round_ndigits=2, numerical_to_label_map = numerical_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6f78fe92-1cff-4d78-8e66-06ae91161cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confidenceinterval import classification_report_with_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c78c4a69-ef2b-43dd-b655-6c733f0b3aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/neurotrialner-notebooks/lib/python3.12/site-packages/confidenceinterval/classification_report.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>Precision CI</th>\n",
       "      <th>Recall CI</th>\n",
       "      <th>F1-Score CI</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Class 0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.400</td>\n",
       "      <td>(0.061, 0.792)</td>\n",
       "      <td>(0.095, 0.905)</td>\n",
       "      <td>(-0.148, 0.948)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Class 1</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.750</td>\n",
       "      <td>(0.301, 0.954)</td>\n",
       "      <td>(0.301, 0.954)</td>\n",
       "      <td>(0.389, 1.111)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Class 2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.857</td>\n",
       "      <td>(0.439, 1.0)</td>\n",
       "      <td>(0.301, 0.954)</td>\n",
       "      <td>(0.547, 1.167)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>micro</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.700</td>\n",
       "      <td>(0.416, 0.984)</td>\n",
       "      <td>(0.416, 0.984)</td>\n",
       "      <td>(0.416, 0.984)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>macro</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.669</td>\n",
       "      <td>(0.545, 0.844)</td>\n",
       "      <td>(0.436, 0.897)</td>\n",
       "      <td>(0.24, 1.098)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Precision  Recall  F1-Score    Precision CI       Recall CI  \\\n",
       "0  Class 0      0.333   0.500     0.400  (0.061, 0.792)  (0.095, 0.905)   \n",
       "1  Class 1      0.750   0.750     0.750  (0.301, 0.954)  (0.301, 0.954)   \n",
       "2  Class 2      1.000   0.750     0.857    (0.439, 1.0)  (0.301, 0.954)   \n",
       "3    micro      0.700   0.700     0.700  (0.416, 0.984)  (0.416, 0.984)   \n",
       "4    macro      0.694   0.667     0.669  (0.545, 0.844)  (0.436, 0.897)   \n",
       "\n",
       "       F1-Score CI Support  \n",
       "0  (-0.148, 0.948)       2  \n",
       "1   (0.389, 1.111)       4  \n",
       "2   (0.547, 1.167)       4  \n",
       "3   (0.416, 0.984)      10  \n",
       "4    (0.24, 1.098)      10  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true, y_pred = [[2, 0, 0, 2, 1, 1, 1, 1,2,2],[2, 0, 1, 0, 1, 0, 1, 1,2,2]]\n",
    "\n",
    "classification_report_with_ci(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a0b3a183-5161-4eac-abe2-c7ad73b4e483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7857142857142857, (0.475, 0.9444444444444444))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from confidenceinterval.bootstrap import bootstrap_ci\n",
    "# You can specify a random generator for reproducability, or pass None\n",
    "y_true, y_pred = [[0, 0, 0, 0, 0 ,0, 1, 1, 1,1,1,0,1,1],[0, 0, 0, 0, 0 ,0, 1, 1, 1,1,1,1,0,0]]\n",
    "\n",
    "random_generator = np.random.default_rng()\n",
    "bootstrap_ci(y_true=y_true,\n",
    "             y_pred=y_pred,\n",
    "             metric=sklearn.metrics.balanced_accuracy_score,\n",
    "             confidence_level=0.95,\n",
    "             n_resamples=9999,\n",
    "             method='bootstrap_bca',\n",
    "             random_state=random_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956dfa03-e7ac-4dad-992e-46a2087de033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurotrialner-notebooks",
   "language": "python",
   "name": "neurotrialner-notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
